# Задача Дирихле для уравнения Пуассона
*Вдохновлено работами osogi, Kuarni.*
## Условие задачи

1. Разобраться в последовательном (1.11) и параллельном алгоритме (1.16) решения задачи Дирихле для уравнения Пуассона из книги В. П. Гергеля
   [“Высокопроизводительные вычисления для
   многоядерных многопроцессорных систем” (2010)](https://github.com/artjomjuferov/university/blob/master/Beljakova/Гергель%20В.П.%20Высокопроизводительные%20вычисления%20для%20многоядерных%20многопроцессорных%20систем%20(2010).pdf).
2. Реализовать последовательный и параллельный алгоритмы.
3. Провести эксперимент, исследующий эффективность (или неэффективность) параллельного алгоритма.

## Условия проведения эксперимента
### Аппаратное обеспечение
- Процессор — **Apple M1 Pro (8 ядер).**
- Оперативная память — **16 GB.**
- Операционная система — **macOS Sonoma 14.0.**
- L1-кэш — **256 KB.**
### Программное обеспечение
- Версия GCC - **13.2.0.**
- Версия OpenMP - **4.5.**

**Во всех экспериментах использовались флаги отпимизации `-O3` и поддержки многопоточности `-fopenmp`.**
### Функции, для которых искалась аппроксимация:
- $`A) \ g(x, y) = 10x^{10} + 10y^{10}`$
- $`B) \ g(x, y) = 100*(1 - 2 * y)*(1 - 2 * x)`$
### Количество повторений
Все вычисления в экспериментах проводились 5 раз, после чего в качестве финального результата бралось среднее арифтметическое полученных значений (если в эксперименте не оговорено иное).

## Обозначения
- $`D`$ - область, на которой задается функция. Для простоты берется единичный квадрат, на котором строится сетка.
- $`N`$ - размер сетки по любой из координат без включения границы.
- $`B`$ - размер стороны блока.
- $`BN`$ - количество блоков.
- $`g(x, y)`$ - функция, к которой приближаем.
- $`f(x, y)`$ - сумма частных производных второго порядка функции $`g(x,y)`$.
- $`EPS`$ - требуемая точность, то есть максимально допустимая разница между результатом приближения и истинным значением функции.
- $`t_b(a)`$ - время выполнения операции $`a`$ на $`b`$ потоках.
- $`iter`$ - количество итераций внешнего цикла в параллельном алгоритме.
- $`ceil(x)`$ - округлить $`x`$ в большую сторону.

## Анализ зависимости времени работы алгоритма от начальных значений функции
### Гипотеза
Время работы алгоритма, а соответственно и число итераций внешнего цикла зависят от числа $`EPS`$, функции $`g(x, y)`$ и начальных значений приближаемой функции.

### Эксперимент
1. Для анализа влияния $`EPS`$ и $`g(x, y)`$ просто запустим алгоритм на разных функциях и $`EPS`$, после чего сделаем замеры.

Условия эксперимента:
- Будем заполнять начальные значения функции нулями.
- $`N`$ - **500.**
- $`B`$ - **32.**
- $`g(x, y)`$ - $`A, \ B`$.

2. Для анализа влияния начальных значений приближаемой функции на время работы алгоритма, рассмотрим два самых простых способа задать начальные значения:
- Заполнить всё нулями.
- Заполнить случайными значениями из некоторого допустимого интервала. 

Условия эксперимента:
- $`N`$ - **500.**
- $`B`$ - **32.**
- $`EPS`$ - **0.01.**
- $`g(x, y)`$ - $`A, \ B`$.
- Потоков - **3.**
- Значения будем брать из интервала $`[-100, 100].`$

### Результат
1. EPS напрамую влияет на время работы алгоритма, что почти очевидно: [табличка](https://docs.google.com/spreadsheets/d/1AKDyXfrxzCEKxxAchtd31ukRfff4sWQDYufzrwduoZs/edit?usp=sharing).
Чем меньше точность, тем большее количество итераций надо сделать.
Также из результатов видно, что достаточно большое влияние на время оказывает сама функция, к которой мы приближаем.

2. Начальные значения приближаемой функции также влияют на время работы алгоритма: [табличка](https://docs.google.com/spreadsheets/d/1AKDyXfrxzCEKxxAchtd31ukRfff4sWQDYufzrwduoZs/edit?usp=sharing).
В среднем при заполнении значений случайными числами из интервала $[-100, 100]`$ алгоритм работает быстрее, чем при заполнении нулями, но не значительно.
Случается даже, что при заполнении случайными числами алгоритм работает медленнее.
Приведенные в таблице значения, для случая, когда значения заполняются случайными числами являются средним арифметическом значений, полученных при 10 запусках алгоритма.

## Анализ эффективности работы параллельного алгоритма на нескольких потоках в сравнии с последовательным алгоритмом

### Ожидаемые показатели
Рассчитаем ожидаемое ускорение при распараллеливании.

#### Последовательный алгоритм
Для обработки сетки размером $`N \times N`$ нам надо сделать $`N^2`$ действий на одну итерацию внешнего цикла. Таких итераций может быть много, их число определяется числом $`EPS`$ и начальными значениями функции, которую приблежаем.
Помимо этого, требуется время на все прочие операции (само приближение и т.д.) - обозначим все такие операции $`C`$. 
Тогда понятно, что для выполнения последовательного алгоритма понадобится время $`t_*(consistent) \approx i * (N^2 * C), \ C \in R`$.
Звездочка у $`t`$ говорит о том, что это будет верно на любом количестве потоков.

#### Параллельный алгоритм
Для обработки одного блока размером $`B`$, по аналогии со временем для выполнения последовательного алгоритма (внутри блока последовательное вычисление):
$`t(approximate \_ block) \approx B^2 * C, \ C \in R.`$
При обработки всей сетки у нас уйдет время на нарастание волны, затухание волны и обработку прочих операций (например, сами подсчеты, синхронизация потоков и т.д.).
Понятно, что на последнее нам понадобится $`C * BN, \ C \in R`$ действий.
Для обработки нарастания волны нам понадобится $`\displaystyle\sum_{i=1}^{BN}
t_*(approximate \_ block)*ceil(i/a)`$ действий. Действительно, мы идем по блокам вдоль сетки, и на каждом шаге пытаемся распределить вычисление $`i`$ блоков на $`a`$ потоков.
Аналогично, для обработки затухания волны: $`\displaystyle\sum_{i=1}^{BN-1}
t_*(approximate \_ block)*ceil(i/a)`$.

Таким образом, на работу алгоритма уйдет время:

$`t_a(approximate) \approx iter * (\displaystyle\sum_{i=1}^{BN} t_*(approximate \ _block) * ceil(i/a) + \displaystyle\sum_{i=1}^{BN-1} t_*(approximate \ _block) * ceil(i/a) + C * BN), \ C \in R.`$

#### Результаты подсчетов
По расчитанным выше формулам было вычеслено ожидаемое ускорение при распараллеливании.
Везде $`iter`$ принималось равным $`1`$, так как распараллеливание происходит внутри внешнего цикла, определяющего число итераций. Таким образом, мы можем корректно рассчитать ускорение, которое будет верно для любого количества итераций.

**Ожидаемые результаты представлены в виде [таблицы](https://docs.google.com/spreadsheets/d/1AKDyXfrxzCEKxxAchtd31ukRfff4sWQDYufzrwduoZs/edit?usp=sharing).**

### Фактические показатели

Замеры проводились в следующих условиях:
- $`EPS`$ - **0.01.**
- $`N`$ - **50, 100, 200, 300, 500, 750, 1000, 2000, 3000.**
- $`B`$ - **16, 32, 64, 128, 256.**
- $`g(x, y)`$ - $`A, \ B`$.
- Начальные значения приближаемой функции заполнялись нулями.

С замерами для каждой функции можно ознакомиться в таблицах: [A](https://docs.google.com/spreadsheets/d/1AKDyXfrxzCEKxxAchtd31ukRfff4sWQDYufzrwduoZs/edit#gid=934965890), [B](https://docs.google.com/spreadsheets/d/1AKDyXfrxzCEKxxAchtd31ukRfff4sWQDYufzrwduoZs/edit#gid=169874415).

### Наблюдения
- На маленьких сектах, размером до **200-250** параллельный алгоритм проигрывает по времени последовательному, причем чем больше используется потоков - тем медленнее работает алгоритм. Предположительно, это возникает из-за неоправданных в данном случае(маленькие сетки) затрат на синхронизацию потоков. Разница между ожидаемым и фактическим значением существенна и возникает из-за того, что при подсчете ожидаемых значений не учитывались затраты на синхронизацию.
- Эффективность параллельной версии начинает наблюдаться на сетках размером **400-500** и особенно видна на крупных сетках размером **>1000**.
- Чем больше размер блока, тем меньше разница между ожидаемым и фактическим значением.
- Ожидаемые и фактические значения плюс-минус соотносятся, особенно на сетках размером **>1000** с блоками **>64**. Однако имеется множество мест, где значения разнятся очень сильно, в основном из-за сильной неточности теорических подсчетов (как минимум не учитываются затраты на синхронизацию).
- Блоки размером **>32** на маленьких сетках (**200-250**) приводят к увелечению времени работы алгоритма.
- Блоки размером **32-64** на средних сетках (**300-1000**) приводят к уменьшению времени работы алгоритма.
- Блоки размером **64-256** на больших сетках (**>1000**) приводят к **значительному** уменьшению времени работы алгоритма.
- Слишком большие блоки приводят к увелечению времени работы алгоритма. Размер блока тут относителен и зависит от размера сетки. Например, для сетки размером **300** блок размером **256** является слишком большим.
- В среднем параллельный алгоритм на **4-5** потоках работал быстрее, чем на **6-8**. Предположительно, это происходит из-за того, что часть процессорного времени для некоторых ядер уделяется на обработку других программ, сигналов и прочего, тем самым есть поток(и) которые некоторое время будут "висеть", не давая алгоритмы перейти на следующую итерацию.
### Результат
- Получено ожидаемое ускорение на сетках, размером от **400-500**. Если в качестве начальных условиях учитывать затраты на синхронизацию, то получено теоретически ожидаемое замедление на сетках размером до **300**. Несмотря на то, что были места, где ожидания не оправдывались(возможные причины в наблюдениях), алгоритм можно считать эффективным, так как в большинстве случаев ускорение работы алгоритма на разном количестве потоков соответствовало с ожиданиями, а иногда даже их превысходило.
- Ускорение времени работы алгоритма **1.16** на разном количестве потоков не зависит от функции, так как на любом количестве потоков у нас предполагается одинаковый результат и количество итераций.
- Выявлено следующее: для максимального ускорения алгоритма необходимо найти "баланс" между размером сетки и размером блока. По результатам экспериментов была построена таблица наиболее отпимальных размеров блоков для разных размеров сетки.

| N     | B        |
|-------|----------|
| 50	   | 16       |
| 100	  | 32	      |
| 200	  | 64	      |
| 300	  | 64	      |
| 500	  | 128      | 
| 750	  | 128	     |
| 1000	 | 128	     | 
| 2000	 | 128-256	 | 
| 3000	 | 256      | 